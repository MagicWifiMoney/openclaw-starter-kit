---
name: self-improving-agent
description: "Captures learnings, verifies work, and logs decisions. Use when: (1) completing a task (verify it worked), (2) making recommendations to Jake (decision format), (3) something goes wrong (incident log), (4) Jake approves/rejects a recommendation (log decision). DON'T use when: quick answers, simple file operations, or casual conversation."
---

# Self-Improving Agent Skill

## Verify â†’ Learn Loop (MANDATORY)

**Never mark work "done" until you VERIFY it actually worked.**

```
1. EXECUTE â†’ Do the work
2. VERIFY â†’ Test/check it actually happened
   - Check live site / run test command / view logs / confirm with API
3. RETRY â†’ If failed, fix and repeat
4. LEARN â†’ Extract lesson before marking done
5. DONE â†’ Only now can you say "complete"
```

### Verification Examples:

**Deploying code (Vercel - MANDATORY):**
- âŒ "Pushed to GitHub, done"
- âœ… "Pushed â†’ Checked Vercel deployment status â†’ Tested live URL â†’ Works âœ“"
- After EVERY git push to a Vercel project: run `vercel ls` or check the Vercel dashboard.

**Creating cron:**
- âœ… "Added â†’ Verified in cron list â†’ Next run scheduled â†’ Done âœ“"

**Updating files:**
- âœ… "Updated â†’ Read file back â†’ Changes present â†’ Done âœ“"

**API changes:**
- âœ… "Updated â†’ Tested with curl â†’ Returns expected data â†’ Done âœ“"

### Extract Learnings:
After verification, ask:
- What went wrong?
- What would prevent this next time?
- What's the better approach?

Write to `memory/YYYY-MM-DD.md` immediately.

## Decision Interface Pattern (MANDATORY)

**Every recommendation MUST end with structured decision format:**

```
ğŸ¯ ACTION 1: [Specific, actionable title]
ğŸ“Š Data: [Numbers/facts driving this recommendation]
âš¡ï¸ Impact: [Expected outcome with metrics]
ğŸ’ª Effort: Low/Med/High

ğŸ¯ ACTION 2: [Next option]
ğŸ“Š Data: [Supporting facts]
âš¡ï¸ Impact: [What changes]
ğŸ’ª Effort: Low/Med/High

Reply: "Approve 1" or "Reject 1 - [reason]"
```

**When to use:**
- Project recommendations
- Strategic choices
- Resource allocation
- Process improvements
- Any decision that affects priorities

### Logging Decisions:

When Jake responds with "Approve X" or "Reject X - reason":
1. Log to `memory/decisions/YYYY-MM.md`
2. Track rejection reason (if rejected)
3. Execute approved action
4. Follow up with outcome

**Log format:**
```markdown
## [Date] - [Action Title]
**Decision:** Approved/Rejected
**Reason:** [If rejected]
**Outcome:** [After execution]
**Learning:** [What this teaches]
```

## Proactive Updates (NON-NEGOTIABLE)

**If you say "I'll update you when X is done" - that's a PROMISE.**

1. **Complete the work**
2. **IMMEDIATELY send the update** (don't wait for next message)
3. **Include:** What was done, any issues, next steps

### Completion Summary Template
```
âœ… [Task name] complete

What shipped:
- Item 1
- Item 2

Issues (if any):
- Thing that failed + why

Next: [What's next or "all done"]
```

### During Multi-Step Work
- "Step 1/3 done, moving to step 2"
- "Hit a snag with X, trying Y instead"
- "All done - here's what shipped"

## Incident Logging

When something goes wrong:
â†’ Append to `memory/incidents.md`: `[date] CATEGORY: what happened â†’ fix`

Categories: ROUTING, FILE, AGENT, CONFIG, EXTERNAL, MEMORY
